import { NextRequest, NextResponse } from "next/server";
import { VIDEO_MODELS, type VideoModel } from "@/lib/types";
import { pickBestModel } from "@/lib/pick-best-model";

interface AgentResponse {
  message: string;
  action?: "generate";
  model?: VideoModel;
  prompt?: string;
  aspect_ratio?: string;
  duration?: number;
}

function parseUserIntent(message: string, selectedModel?: VideoModel): AgentResponse {
  const lowerMsg = message.toLowerCase();

  // Detect model selection from message text
  let detectedModel: VideoModel | undefined;
  if (lowerMsg.includes("kling")) detectedModel = "kling";
  else if (lowerMsg.includes("veo")) detectedModel = "veo";
  else if (lowerMsg.includes("sora")) detectedModel = "sora";

  // Detect aspect ratio
  let aspectRatio: string | undefined;
  if (lowerMsg.includes("vertical") || lowerMsg.includes("9:16"))
    aspectRatio = "9:16";
  else if (lowerMsg.includes("cuadrado") || lowerMsg.includes("square") || lowerMsg.includes("1:1"))
    aspectRatio = "1:1";
  else if (lowerMsg.includes("horizontal") || lowerMsg.includes("16:9"))
    aspectRatio = "16:9";

  // Detect generation intent
  const generateKeywords = [
    "genera", "generar", "crea", "crear", "haz", "hacer",
    "generate", "create", "make",
    "quiero un video", "quiero un v√≠deo",
    "hazme un video", "hazme un v√≠deo",
  ];

  const wantsGeneration = generateKeywords.some((kw) => lowerMsg.includes(kw));

  // Detect greeting
  const greetings = ["hola", "hello", "hi", "hey", "buenas", "qu√© tal"];
  const isGreeting = greetings.some((g) => lowerMsg.includes(g));

  // Detect help request
  const helpKeywords = ["ayuda", "help", "c√≥mo", "como", "qu√© puedo", "que puedo", "modelos"];
  const wantsHelp = helpKeywords.some((kw) => lowerMsg.includes(kw));

  if (isGreeting && !wantsGeneration) {
    return {
      message:
        "üëã ¬°Hola! Soy tu asistente de generaci√≥n de v√≠deos con IA.\n\n" +
        "Puedo crear v√≠deos usando estos modelos:\n\n" +
        "üé¨ **Kling 2.1** ‚Äî V√≠deos de alta calidad con movimientos de c√°mara precisos\n" +
        "üåü **VEO 3** ‚Äî Modelo de Google con audio nativo profesional\n" +
        "üé• **Sora 2** ‚Äî Modelo de OpenAI con detalle cinematogr√°fico\n\n" +
        "Dime qu√© v√≠deo quieres crear. Por ejemplo:\n" +
        '*"Genera con Kling un atardecer en la playa con olas suaves"*',
    };
  }

  if (wantsHelp && !wantsGeneration) {
    const modelsInfo = VIDEO_MODELS.map(
      (m) => `‚Ä¢ **${m.name}**: ${m.description} (hasta ${m.maxDuration}s)`
    ).join("\n");

    return {
      message:
        "Estos son los modelos disponibles:\n\n" +
        modelsInfo +
        "\n\n" +
        "Para generar un v√≠deo, escribe algo como:\n" +
        '*"Crea con Sora un bosque m√°gico con luci√©rnagas"*\n\n' +
        "Tambi√©n puedes especificar:\n" +
        "‚Ä¢ **Formato**: horizontal (16:9), vertical (9:16), cuadrado (1:1)\n" +
        "‚Ä¢ **Modelo**: Kling, VEO o Sora",
    };
  }

  if (wantsGeneration) {
    // Extract the video description prompt
    // Remove the generation keywords and model name to get the actual prompt
    let videoPrompt = message;

    // Remove common prefixes
    const prefixPatterns = [
      /^(genera|generar|crea|crear|haz|hacer|generate|create|make)\s*(un\s*)?(video|v√≠deo)?\s*(con|using|with)?\s*(kling|veo|sora)?\s*(de|about|un|una|:)?\s*/i,
      /^(quiero|hazme)\s*(un\s*)?(video|v√≠deo)\s*(con|de|using)?\s*(kling|veo|sora)?\s*(de|about|:)?\s*/i,
    ];

    for (const pattern of prefixPatterns) {
      videoPrompt = videoPrompt.replace(pattern, "").trim();
    }

    // If prompt is too short after cleanup, use original
    if (videoPrompt.length < 10) {
      videoPrompt = message;
    }

    if (!detectedModel) {
      detectedModel = (!selectedModel || selectedModel === "auto")
        ? pickBestModel(videoPrompt)
        : selectedModel;
    }

    const modelConfig = VIDEO_MODELS.find((m) => m.id === detectedModel);

    return {
      message:
        `üé¨ Generando v√≠deo con **${modelConfig?.name}**...\n\n` +
        `üìù Prompt: *"${videoPrompt}"*\n` +
        `üìê Formato: ${aspectRatio || "16:9"}\n\n` +
        "Esto puede tomar entre 30 segundos y unos minutos. Te avisar√© cuando est√© listo.",
      action: "generate",
      model: detectedModel,
      prompt: videoPrompt,
      aspect_ratio: aspectRatio || "16:9",
      duration: modelConfig?.defaultDuration,
    };
  }

  // Default: treat as a video prompt with default model
  return {
    message:
      "No estoy seguro de lo que quieres hacer. Aqu√≠ tienes algunas opciones:\n\n" +
      '‚Ä¢ **Generar v√≠deo**: *"Genera con Kling un paisaje futurista"*\n' +
      '‚Ä¢ **Ver modelos**: *"¬øQu√© modelos hay disponibles?"*\n' +
      '‚Ä¢ **Ayuda**: *"Ayuda"*\n\n' +
      "Tambi√©n puedes seleccionar un modelo y escribir tu prompt directamente.",
  };
}

export async function POST(request: NextRequest) {
  try {
    const { message, model } = await request.json();

    if (!message) {
      return NextResponse.json(
        { error: "message is required" },
        { status: 400 }
      );
    }

    const response = parseUserIntent(message, model);

    return NextResponse.json(response);
  } catch (error) {
    console.error("Chat error:", error);
    return NextResponse.json(
      { error: "Internal server error" },
      { status: 500 }
    );
  }
}
